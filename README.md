# ğŸš€ Pipeline de Dados em Tempo Real

## Kafka + Spark Streaming + Postgres + Elasticsearch + Superset + Kibana

Pipeline completo para processamento de eventos em tempo real, com armazenamento, agregaÃ§Ãµes e visualizaÃ§Ã£o.

---

## ğŸ“‹ Arquitetura

```text
Kafka â†’ Spark Streaming â†’ Postgres + Elasticsearch
                              â†“              â†“
                         Superset        Kibana
```

### Componentes

- **Kafka**: IngestÃ£o de eventos em tempo real
- **Zookeeper**: CoordenaÃ§Ã£o do Kafka
- **Spark**: Processamento e transformaÃ§Ã£o dos dados
- **Postgres**: Armazenamento estruturado
- **Elasticsearch**: IndexaÃ§Ã£o para busca e analytics
- **Superset**: Dashboards e visualizaÃ§Ãµes
- **Kibana**: VisualizaÃ§Ã£o de logs e mÃ©tricas
- **PgAdmin**: Interface para gerenciar Postgres

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
.
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ Dockerfile.spark            # Imagem customizada do Spark
â”œâ”€â”€ spark_app.py               # Pipeline Spark (Kafka â†’ Postgres/ES)
â”œâ”€â”€ kafka_producer.py          # Produtor de eventos de teste
â”œâ”€â”€ create_tables.sql          # Schema do banco de dados
â”œâ”€â”€ init_database.sh           # Script para criar tabelas
â”œâ”€â”€ init_superset.sh           # Script para inicializar Superset
â”œâ”€â”€ run_spark.sh               # Script para executar Spark job
â”œâ”€â”€ test_pipeline.sh           # Teste end-to-end
â”œâ”€â”€ superset_mcp.py            # ğŸ¤– Servidor MCP (NOVO!)
â”œâ”€â”€ test_mcp.py                # Testes do servidor MCP
â”œâ”€â”€ setup_mcp.sh               # Setup automatizado do MCP
â”œâ”€â”€ MCP_DOCUMENTATION.md       # DocumentaÃ§Ã£o completa do MCP
â””â”€â”€ README.md                  # Este arquivo
```

---

## ğŸ¤– Servidor MCP (Model Context Protocol)

**NOVO!** Este projeto agora inclui um servidor MCP que permite controlar e monitorar o pipeline atravÃ©s de linguagem natural ou chamadas programÃ¡ticas.

### InÃ­cio RÃ¡pido do MCP

```bash
# Setup automatizado (recomendado)
chmod +x setup_mcp.sh
./setup_mcp.sh

# OU setup manual:
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Ferramentas DisponÃ­veis

- ğŸ‘ï¸ **Observabilidade**: `get_pipeline_status()`, `check_kafka_lag()`, `get_spark_metrics()`
- ğŸ’¾ **Dados**: `query_raw_events()`, `search_elasticsearch()`
- ğŸ•¹ï¸ **Controle**: `restart_service()`, `inject_event()`

### Teste RÃ¡pido

```bash
source venv/bin/activate
python test_mcp.py
```

ğŸ“– **DocumentaÃ§Ã£o completa**: Veja [MCP_DOCUMENTATION.md](MCP_DOCUMENTATION.md)

---

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Subir a infraestrutura

```bash
# Subir todos os containers
docker compose up -d --build

# Verificar status
docker compose ps

# Ver logs
docker compose logs -f
```

### 2. Criar tabelas no Postgres

```bash
chmod +x init_database.sh
./init_database.sh
```

### 3. Inicializar Superset

```bash
chmod +x init_superset.sh
./init_superset.sh
```

### 4. Criar tÃ³pico Kafka

```bash
docker exec kafka kafka-topics --create \
    --topic eventos \
    --bootstrap-server localhost:9092 \
    --partitions 3 \
    --replication-factor 1
```

### 5. Executar o pipeline Spark

```bash
chmod +x run_spark.sh
./run_spark.sh
```

### 6. Enviar eventos de teste

```bash
# Instalar dependÃªncia
pip3 install kafka-python

# Executar produtor
python3 kafka_producer.py
```

---

## ğŸ§ª Teste Completo

Execute o script de teste end-to-end:

```bash
chmod +x test_pipeline.sh
./test_pipeline.sh
```

---

## ğŸŒ Acessos

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| **Spark Master UI** | <http://localhost:8080> | - |
| **Spark Worker UI** | <http://localhost:8081> | - |
| **Superset** | <http://localhost:8088> | admin / admin |
| **Kibana** | <http://localhost:5601> | - |
| **PgAdmin** | <http://localhost:5050> | <admin@admin.com> / admin |
| **Elasticsearch** | <http://localhost:9200> | - |
| **Kafka** | localhost:29092 | - |
| **Postgres** | localhost:5432 | superset / superset |

---

## ğŸ“Š Estrutura de Dados

### Tabela: `eventos_raw`

Eventos brutos consumidos do Kafka.

| Coluna | Tipo | DescriÃ§Ã£o |
|--------|------|-----------|
| id | VARCHAR | ID Ãºnico do evento |
| usuario | VARCHAR | Identificador do usuÃ¡rio |
| evento | VARCHAR | Tipo de evento |
| valor | DOUBLE | Valor monetÃ¡rio |
| timestamp | TIMESTAMP | Data/hora do evento |
| categoria | VARCHAR | Categoria do evento |
| processado_em | TIMESTAMP | Timestamp do processamento |

### Tabela: `eventos_agregados`

AgregaÃ§Ãµes por janela de tempo (5 minutos).

| Coluna | Tipo | DescriÃ§Ã£o |
|--------|------|-----------|
| janela_inicio | TIMESTAMP | InÃ­cio da janela |
| janela_fim | TIMESTAMP | Fim da janela |
| categoria | VARCHAR | Categoria |
| evento | VARCHAR | Tipo de evento |
| total_eventos | BIGINT | Total de eventos |
| valor_medio | DOUBLE | Valor mÃ©dio |
| valor_total | DOUBLE | Valor total |
| processado_em | TIMESTAMP | Timestamp do processamento |

### Views

- **vw_eventos_ultimas_24h**: Resumo das Ãºltimas 24 horas
- **vw_eventos_por_hora**: Eventos agregados por hora (Ãºltimos 7 dias)

---

## ğŸ”§ Comandos Ãšteis

### Docker

```bash
# Parar todos os containers
docker compose down

# Reiniciar serviÃ§o especÃ­fico
docker compose restart spark-master

# Ver logs de um serviÃ§o
docker compose logs -f kafka

# Limpar volumes (CUIDADO: apaga dados)
docker compose down -v
```

### Kafka

```bash
# Listar tÃ³picos
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Consumir mensagens
docker exec kafka kafka-console-consumer \
    --topic eventos \
    --bootstrap-server localhost:9092 \
    --from-beginning

# Ver detalhes do tÃ³pico
docker exec kafka kafka-topics --describe \
    --topic eventos \
    --bootstrap-server localhost:9092
```

### Postgres

```bash
# Conectar ao banco
docker exec -it postgres psql -U superset -d superset

# Ver tabelas
docker exec postgres psql -U superset -d superset -c "\dt"

# Contar eventos
docker exec postgres psql -U superset -d superset -c \
    "SELECT COUNT(*) FROM eventos_raw;"
```

### Elasticsearch

```bash
# Ver Ã­ndices
curl http://localhost:9200/_cat/indices?v

# Contar documentos
curl http://localhost:9200/eventos/_count

# Buscar documentos
curl http://localhost:9200/eventos/_search?pretty
```

---

## ğŸ“ˆ Configurando Superset

1. Acesse <http://localhost:8088> (admin/admin)
2. **Adicionar Database**:
   - Settings â†’ Database Connections â†’ + Database
   - SQLAlchemy URI: `postgresql://superset:superset@postgres:5432/superset`
3. **Criar Dataset**:
   - Datasets â†’ + Dataset
   - Selecione as
