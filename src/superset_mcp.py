import asyncio
import logging
import json
import os
from typing import Any, List, Dict, Optional

# MCP Imports
from mcp.server.fastmcp import FastMCP

# Library Imports
import docker
import psycopg2
from kafka import KafkaAdminClient  # Isso funcionarÃ¡ com kafka-python-ng
from kafka import KafkaAdminClient
from kafka.errors import KafkaError
import requests

# ConfiguraÃ§Ã£o de Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("superset-mcp")

# Inicializar FastMCP
mcp = FastMCP("Superset Control Plane")

# ConfiguraÃ§Ãµes do Ambiente (assumindo execuÃ§Ã£o local ou via docker network)
# Se rodar fora do docker, localhost. Se dentro, usar nomes dos serviÃ§os.
# Vamos assumir execuÃ§Ã£o local (host) acessando portas expostas.
DOCKER_SOCK = "unix://var/run/docker.sock"
POSTGRES_DSN = "postgresql://superset:superset@localhost:5432/superset"
KAFKA_BOOTSTRAP = "localhost:29092"
ELASTICSEARCH_URL = "http://localhost:9200"

# --- Ferramentas de Observabilidade ---

@mcp.tool()
def get_pipeline_status() -> str:
    """
    Retorna o status de saÃºde de todos os containers do pipeline SUPERSET.
    Verifica se estÃ£o rodando (Up) ou parados.
    """
    try:
        client = docker.DockerClient(base_url=DOCKER_SOCK)
        containers = client.containers.list(all=True)
        
        status_report = []
        superset_containers = [c for c in containers if "superset" in c.name.lower() or "kafka" in c.name.lower() or "spark" in c.name.lower() or "postgres" in c.name.lower() or "elastic" in c.name.lower()]
        
        if not superset_containers:
            return "âš ï¸ Nenhum container do pipeline SUPERSET encontrado. Verifique se o docker compose foi iniciado."

        for container in superset_containers:
            state = container.status
            icon = "ğŸŸ¢" if state == "running" else "ğŸ”´"
            status_report.append(f"{icon} **{container.name}**: {state} ({container.status})")
            
        return "\n".join(status_report)
    except Exception as e:
        return f"âŒ Erro ao verificar Docker: {str(e)}"

@mcp.tool()
def check_kafka_lag() -> str:
    """
    Verifica se hÃ¡ atraso (lag) no consumo de mensagens do Kafka.
    Isso indica se o Spark Streaming estÃ¡ dando conta do volume de dados.
    """
    # Nota: Calcular lag exato requer consultar offsets do consumer group.
    # Como simplificaÃ§Ã£o, vamos checar se o tÃ³pico existe e se estÃ¡ acessÃ­vel.
    try:
        admin = KafkaAdminClient(bootstrap_servers=KAFKA_BOOTSTRAP)
        topics = admin.list_topics()
        
        if "eventos" not in topics:
            return "âš ï¸ TÃ³pico 'eventos' nÃ£o encontrado no Kafka. O pipeline pode nÃ£o ter sido inicializado."
            
        # Para lag real, precisariamos da API do ConsumerGroup, que Ã© mais complexa via kafka-python.
        # Vamos retornar o status bÃ¡sico por enquanto.
        return f"âœ… Kafka acessÃ­vel. TÃ³picos encontrados: {', '.join(topics)}"
    except Exception as e:
        return f"âŒ Erro ao conectar no Kafka: {str(e)}"

@mcp.tool()
def get_spark_metrics() -> str:
    """
    Tenta obter mÃ©tricas bÃ¡sicas da UI do Spark Master.
    """
    try:
        # A UI do Master geralmente fica na 8080. A API JSON fica na 8080/json/
        resp = requests.get("http://localhost:8080/json/", timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            active_apps = len(data.get('activeapps', []))
            workers = len(data.get('workers', []))
            status = data.get('status', 'UNKNOWN')
            return f"âš¡ Spark Master ({status}): {workers} Workers ativos, {active_apps} AplicaÃ§Ãµes rodando."
        else:
            return f"âš ï¸ Spark Master respondeu com status {resp.status_code}"
    except Exception as e:
        return f"âŒ NÃ£o foi possÃ­vel contatar Spark Master na porta 8080: {str(e)}"

# --- Ferramentas de Dados (Iniciais) ---

@mcp.tool()
def query_raw_events(limit: int = 5) -> str:
    """
    Consulta os Ãºltimos N eventos brutos gravados no Postgres.
    Ãštil para verificar se os dados estÃ£o chegando no banco.
    """
    try:
        conn = psycopg2.connect(POSTGRES_DSN)
        cur = conn.cursor()
        
        query = "SELECT * FROM eventos_raw ORDER BY timestamp DESC LIMIT %s;"
        cur.execute(query, (limit,))
        rows = cur.fetchall()
        
        if not rows:
            return "ğŸ“­ Nenhum evento encontrado na tabela 'eventos_raw'."
            
        # Formatar resultado
        colnames = [desc[0] for desc in cur.description]
        result = []
        for row in rows:
            row_dict = dict(zip(colnames, row))
            result.append(str(row_dict))
            
        cur.close()
        conn.close()
        return "\n\n".join(result)
    except Exception as e:
        return f"âŒ Erro ao consultar Postgres: {str(e)}"



@mcp.tool()
def search_elasticsearch(query: str, index: str = "eventos") -> str:
    """
    Busca documentos no Elasticsearch usando uma query string simples (Lucene syntax).
    Ex: 'categoria:ecommerce AND valor:>500'
    """
    try:
        # Usar _search com q= parameter para query string simples
        url = f"{ELASTICSEARCH_URL}/{index}/_search"
        params = {"q": query, "size": 5, "pretty": "true"}
        
        resp = requests.get(url, params=params)
        
        if resp.status_code != 200:
            return f"âš ï¸ Elasticsearch retornou erro {resp.status_code}: {resp.text}"
            
        data = resp.json()
        hits = data.get("hits", {}).get("hits", [])
        
        if not hits:
            return f"ğŸ“­ Nenhum resultado encontrado para '{query}' no Ã­ndice '{index}'."
            
        results = []
        for hit in hits:
            source = hit.get("_source", {})
            results.append(json.dumps(source, indent=2))
            
        return "\n---\n".join(results)
    except Exception as e:
        return f"âŒ Erro ao buscar no Elasticsearch: {str(e)}"

# --- Ferramentas de Controle (Ops) ---

@mcp.tool()
def restart_service(service_name: str) -> str:
    """
    Reinicia um container especÃ­fico do pipeline.
    Ex: 'spark-worker', 'superset', 'kafka'.
    """
    try:
        client = docker.DockerClient(base_url=DOCKER_SOCK)
        # Buscar container por nome aproximado
        containers = client.containers.list(all=True)
        target = next((c for c in containers if service_name in c.name), None)
        
        if not target:
            return f"âš ï¸ Container com nome similar a '{service_name}' nÃ£o encontrado."
            
        target.restart()
        return f"ğŸ”„ ServiÃ§o '{target.name}' reiniciado com sucesso!"
    except Exception as e:
        return f"âŒ Erro ao reiniciar serviÃ§o: {str(e)}"

@mcp.tool()
def inject_event(evento_tipo: str, valor: float, usuario: str = "manual_user") -> str:
    """
    Injeta um evento manual no Kafka para teste.
    """
    try:
        from kafka import KafkaProducer
        import uuid
        from datetime import datetime
        
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
        
        evento = {
            'id': str(uuid.uuid4()),
            'usuario': usuario,
            'evento': evento_tipo,
            'valor': valor,
            'timestamp': datetime.now().isoformat(),
            'categoria': 'teste_manual'
        }
        
        producer.send('eventos', value=evento)
        producer.flush()
        producer.close()
        
        return f"âœ… Evento injetado com sucesso: {json.dumps(evento)}"
    except Exception as e:
        return f"âŒ Erro ao injetar evento: {str(e)}"


# ==============================================================================
# INTEGRAÃ‡ÃƒO SUPABASE (LOVABLE SITE)
# ==============================================================================

@mcp.tool()
def sync_leads_from_supabase(limit: int = 100, hours_ago: int = 24) -> str:
    """
    Sincroniza leads do Supabase (LOVABLE SITE) para o pipeline Kafka.
    
    Args:
        limit: NÃºmero mÃ¡ximo de leads a sincronizar
        hours_ago: Considerar apenas leads criados nas Ãºltimas N horas
    
    Exemplo:
        sync_leads_from_supabase(limit=50, hours_ago=12)
    """
    try:
        from supabase_to_kafka import sync_leads_to_kafka
        
        result = sync_leads_to_kafka(limit=limit, hours_ago=hours_ago)
        
        if result.get("status") == "success":
            total_processed = result.get("total_processed", 0)
            total_found = result.get("total_found", 0)
            summary = result.get("summary", {})
            
            response = f"""âœ… SincronizaÃ§Ã£o concluÃ­da!

ğŸ“Š Resumo:
â€¢ Total encontrado: {total_found} leads
â€¢ Total enviado ao Kafka: {total_processed} eventos
â€¢ PerÃ­odo: Ãšltimas {hours_ago}h
â€¢ Score mais alto: {summary.get('highest_score', 'N/A')}
â€¢ Score mÃ©dio: {summary.get('average_score', 'N/A'):.1f}

ğŸ“ˆ Por Status:"""
            
            for status, count in summary.get('status_breakdown', {}).items():
                response += f"\n   â€¢ {status}: {count}"
                
            return response
        else:
            return f"âŒ Erro: {result.get('error', 'Erro desconhecido')}"
            
    except Exception as e:
        return f"âŒ Erro ao sincronizar leads: {str(e)}"


@mcp.tool()
def sync_chat_sessions_from_supabase(limit: int = 50, hours_ago: int = 24) -> str:
    """
    Sincroniza sessÃµes de chat do Supabase para o pipeline Kafka.
    
    Args:
        limit: NÃºmero mÃ¡ximo de sessÃµes a sincronizar
        hours_ago: Considerar apenas sessÃµes nas Ãºltimas N  horas
    
    Exemplo:
        sync_chat_sessions_from_supabase(limit=30, hours_ago=6)
    """
    try:
        from supabase_to_kafka import sync_chat_sessions_to_kafka
        
        result = sync_chat_sessions_to_kafka(limit=limit, hours_ago=hours_ago)
        
        if result.get("status") == "success":
            total_processed = result.get("total_processed", 0)
            total_found = result.get("total_found", 0)
            
            return f"""âœ… SincronizaÃ§Ã£o de sessÃµes concluÃ­da!

ğŸ“Š Resumo:
â€¢ Total encontrado: {total_found} sessÃµes
â€¢ Total enviado ao Kafka: {total_processed} eventos
â€¢ PerÃ­odo: Ãšltimas {hours_ago}h
â€¢ TÃ³pico Kafka: {result.get('topic')}"""
        else:
            return f"âŒ Erro: {result.get('error', 'Erro desconhecido')}"
            
    except Exception as e:
        return f"âŒ Erro ao sincronizar sessÃµes: {str(e)}"


@mcp.tool()
def get_supabase_dashboard() -> str:
    """
    ObtÃ©m estatÃ­sticas gerais do Supabase (LOVABLE SITE).
    
    Mostra mÃ©tricas de leads, qualificaÃ§Ã£o, sessÃµes ativas, etc.
    """
    try:
        from supabase_to_kafka import get_supabase_stats
        
        stats= get_supabase_stats()
        
        if "error" in stats:
            return f"âŒ Erro: {stats.get('error')}"
        
        return f"""ğŸ“Š Dashboard Supabase - {stats.get('database')}

ğŸ¯ Leads:
   â€¢ Total de leads: {stats.get('total_leads')}
   â€¢ Leads qualificados (score â‰¥ 50): {stats.get('qualified_leads')}
   â€¢ Taxa de qualificaÃ§Ã£o: {stats.get('qualification_rate')}%
   â€¢ Leads nas Ãºltimas 24h: {stats.get('recent_leads_24h')}

ğŸ’¬ SessÃµes:
   â€¢ SessÃµes ativas: {stats.get('active_sessions')}

ğŸ”— ConexÃ£o:
   â€¢ URL: {stats.get('supabase_url')}
   â€¢ Status: âœ… Conectado"""
    except Exception as e:
        return f"âŒ Erro ao obter estatÃ­sticas: {str(e)}"


if __name__ == "__main__":
    mcp.run()
