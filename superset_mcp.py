import asyncio
import logging
import json
import os
from typing import Any, List, Dict, Optional

# MCP Imports
from mcp.server.fastmcp import FastMCP

# Library Imports
import docker
import psycopg2
from kafka import KafkaAdminClient  # Isso funcionar√° com kafka-python-ng
from kafka import KafkaAdminClient
from kafka.errors import KafkaError
import requests

# Configura√ß√£o de Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("superset-mcp")

# Inicializar FastMCP
mcp = FastMCP("Superset Control Plane")

# Configura√ß√µes do Ambiente (assumindo execu√ß√£o local ou via docker network)
# Se rodar fora do docker, localhost. Se dentro, usar nomes dos servi√ßos.
# Vamos assumir execu√ß√£o local (host) acessando portas expostas.
DOCKER_SOCK = "unix://var/run/docker.sock"
POSTGRES_DSN = "postgresql://superset:superset@localhost:5432/superset"
KAFKA_BOOTSTRAP = "localhost:29092"
ELASTICSEARCH_URL = "http://localhost:9200"

# --- Ferramentas de Observabilidade ---

@mcp.tool()
def get_pipeline_status() -> str:
    """
    Retorna o status de sa√∫de de todos os containers do pipeline SUPERSET.
    Verifica se est√£o rodando (Up) ou parados.
    """
    try:
        client = docker.DockerClient(base_url=DOCKER_SOCK)
        containers = client.containers.list(all=True)
        
        status_report = []
        superset_containers = [c for c in containers if "superset" in c.name.lower() or "kafka" in c.name.lower() or "spark" in c.name.lower() or "postgres" in c.name.lower() or "elastic" in c.name.lower()]
        
        if not superset_containers:
            return "‚ö†Ô∏è Nenhum container do pipeline SUPERSET encontrado. Verifique se o docker compose foi iniciado."

        for container in superset_containers:
            state = container.status
            icon = "üü¢" if state == "running" else "üî¥"
            status_report.append(f"{icon} **{container.name}**: {state} ({container.status})")
            
        return "\n".join(status_report)
    except Exception as e:
        return f"‚ùå Erro ao verificar Docker: {str(e)}"

@mcp.tool()
def check_kafka_lag() -> str:
    """
    Verifica se h√° atraso (lag) no consumo de mensagens do Kafka.
    Isso indica se o Spark Streaming est√° dando conta do volume de dados.
    """
    # Nota: Calcular lag exato requer consultar offsets do consumer group.
    # Como simplifica√ß√£o, vamos checar se o t√≥pico existe e se est√° acess√≠vel.
    try:
        admin = KafkaAdminClient(bootstrap_servers=KAFKA_BOOTSTRAP)
        topics = admin.list_topics()
        
        if "eventos" not in topics:
            return "‚ö†Ô∏è T√≥pico 'eventos' n√£o encontrado no Kafka. O pipeline pode n√£o ter sido inicializado."
            
        # Para lag real, precisariamos da API do ConsumerGroup, que √© mais complexa via kafka-python.
        # Vamos retornar o status b√°sico por enquanto.
        return f"‚úÖ Kafka acess√≠vel. T√≥picos encontrados: {', '.join(topics)}"
    except Exception as e:
        return f"‚ùå Erro ao conectar no Kafka: {str(e)}"

@mcp.tool()
def get_spark_metrics() -> str:
    """
    Tenta obter m√©tricas b√°sicas da UI do Spark Master.
    """
    try:
        # A UI do Master geralmente fica na 8080. A API JSON fica na 8080/json/
        resp = requests.get("http://localhost:8080/json/", timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            active_apps = len(data.get('activeapps', []))
            workers = len(data.get('workers', []))
            status = data.get('status', 'UNKNOWN')
            return f"‚ö° Spark Master ({status}): {workers} Workers ativos, {active_apps} Aplica√ß√µes rodando."
        else:
            return f"‚ö†Ô∏è Spark Master respondeu com status {resp.status_code}"
    except Exception as e:
        return f"‚ùå N√£o foi poss√≠vel contatar Spark Master na porta 8080: {str(e)}"

# --- Ferramentas de Dados (Iniciais) ---

@mcp.tool()
def query_raw_events(limit: int = 5) -> str:
    """
    Consulta os √∫ltimos N eventos brutos gravados no Postgres.
    √ötil para verificar se os dados est√£o chegando no banco.
    """
    try:
        conn = psycopg2.connect(POSTGRES_DSN)
        cur = conn.cursor()
        
        query = "SELECT * FROM eventos_raw ORDER BY timestamp DESC LIMIT %s;"
        cur.execute(query, (limit,))
        rows = cur.fetchall()
        
        if not rows:
            return "üì≠ Nenhum evento encontrado na tabela 'eventos_raw'."
            
        # Formatar resultado
        colnames = [desc[0] for desc in cur.description]
        result = []
        for row in rows:
            row_dict = dict(zip(colnames, row))
            result.append(str(row_dict))
            
        cur.close()
        conn.close()
        return "\n\n".join(result)
    except Exception as e:
        return f"‚ùå Erro ao consultar Postgres: {str(e)}"



@mcp.tool()
def search_elasticsearch(query: str, index: str = "eventos") -> str:
    """
    Busca documentos no Elasticsearch usando uma query string simples (Lucene syntax).
    Ex: 'categoria:ecommerce AND valor:>500'
    """
    try:
        # Usar _search com q= parameter para query string simples
        url = f"{ELASTICSEARCH_URL}/{index}/_search"
        params = {"q": query, "size": 5, "pretty": "true"}
        
        resp = requests.get(url, params=params)
        
        if resp.status_code != 200:
            return f"‚ö†Ô∏è Elasticsearch retornou erro {resp.status_code}: {resp.text}"
            
        data = resp.json()
        hits = data.get("hits", {}).get("hits", [])
        
        if not hits:
            return f"üì≠ Nenhum resultado encontrado para '{query}' no √≠ndice '{index}'."
            
        results = []
        for hit in hits:
            source = hit.get("_source", {})
            results.append(json.dumps(source, indent=2))
            
        return "\n---\n".join(results)
    except Exception as e:
        return f"‚ùå Erro ao buscar no Elasticsearch: {str(e)}"

# --- Ferramentas de Controle (Ops) ---

@mcp.tool()
def restart_service(service_name: str) -> str:
    """
    Reinicia um container espec√≠fico do pipeline.
    Ex: 'spark-worker', 'superset', 'kafka'.
    """
    try:
        client = docker.DockerClient(base_url=DOCKER_SOCK)
        # Buscar container por nome aproximado
        containers = client.containers.list(all=True)
        target = next((c for c in containers if service_name in c.name), None)
        
        if not target:
            return f"‚ö†Ô∏è Container com nome similar a '{service_name}' n√£o encontrado."
            
        target.restart()
        return f"üîÑ Servi√ßo '{target.name}' reiniciado com sucesso!"
    except Exception as e:
        return f"‚ùå Erro ao reiniciar servi√ßo: {str(e)}"

@mcp.tool()
def inject_event(evento_tipo: str, valor: float, usuario: str = "manual_user") -> str:
    """
    Injeta um evento manual no Kafka para teste.
    """
    try:
        from kafka import KafkaProducer
        import uuid
        from datetime import datetime
        
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
        
        evento = {
            'id': str(uuid.uuid4()),
            'usuario': usuario,
            'evento': evento_tipo,
            'valor': valor,
            'timestamp': datetime.now().isoformat(),
            'categoria': 'teste_manual'
        }
        
        producer.send('eventos', value=evento)
        producer.flush()
        producer.close()
        
        return f"‚úÖ Evento injetado com sucesso: {json.dumps(evento)}"
    except Exception as e:
        return f"‚ùå Erro ao injetar evento: {str(e)}"

if __name__ == "__main__":
    mcp.run()
