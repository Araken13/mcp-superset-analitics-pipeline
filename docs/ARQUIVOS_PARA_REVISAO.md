# üîç Arquivos que Precisam de Revis√£o - SUPERSET

**Data da An√°lise:** 2025-12-05  
**Status Geral do Sistema:** ‚úÖ Funcional (com ressalvas)

---

## üî¥ CR√çTICO - Requer Corre√ß√£o Imediata

### 1. `spark_supabase.py`

**Status:** ‚ùå N√£o funcional  
**Problema:** Job n√£o inicia quando submetido ao Spark  
**Impacto:** N√£o consegue processar dados do Supabase na tabela `leads` (estrutura completa)

**Erros Identificados:**

- Job √© submetido mas n√£o aparece na Spark Master UI
- Sem erros vis√≠veis nos logs
- Poss√≠vel problema no c√≥digo Python ou depend√™ncias

**Solu√ß√£o Sugerida:**

1. Revisar o c√≥digo line-by-line
2. Testar localmente antes de submeter
3. Verificar schema do Kafka vs schema esperado pelo c√≥digo
4. Adicionar logging detalhado

**Workaround Atual:**

- Usar `spark_app.py` (que grava em `eventos_raw`)
- Leads do Supabase ficam gravados em `eventos_raw`, n√£o na tabela `leads`

**Arquivo:**

```python
# Localiza√ß√£o: /home/renan3/SUPERSET/spark_supabase.py
# √öltima modifica√ß√£o: 2025-12-04
```

---

## ‚ö†Ô∏è ATEN√á√ÉO - Funcionando mas com Issues

### 2. `spark_app.py`

**Status:** ‚úÖ Funcional (com duplica√ß√£o)  
**Problema:** Criando duplicatas no Elasticsearch  
**Impacto:** Baixo - Postgres est√° protegido por PK, apenas Elasticsearch tem duplicatas

**Detalhes:**

- Grava 1x no Postgres (correto - PK impede duplica√ß√£o)
- Grava 3x no Elasticsearch (incorreto)
- Causa: M√∫ltiplos jobs rodaram simultaneamente em testes

**Solu√ß√£o Sugerida:**

1. Adicionar verifica√ß√£o de job rodando antes de submeter novo
2. Implementar `mode("append")` com upsert no Elasticsearch
3. Limpar √≠ndice Elasticsearch e reprocessar

**C√≥digo Problem√°tico:**

```python
# Em spark_app.py, linha ~180-200
df_parsed.writeStream \
    .format("org.elasticsearch.spark.sql") \
    .outputMode("append") \
    .option("checkpointLocation", "/tmp/checkpoint-elasticsearch") \
    .option("es.resource", "eventos") \
    .start()
```

**Solu√ß√£o:**

```python
# Adicionar op√ß√£o de upsert por ID
.option("es.mapping.id", "id") \
.option("es.write.operation", "upsert")
```

---

### 3. Checkpoints do Spark

**Status:** ‚ö†Ô∏è Requer limpeza  
**Problema:** Checkpoints antigos causam conflitos  
**Impacto:** M√©dio - Novos jobs podem n√£o processar dados antigos

**Localiza√ß√£o:**

- `/tmp/spark-checkpoint-supabase`
- `/tmp/spark-checkpoint-eventos`
- `/tmp/checkpoint-elasticsearch`

**Solu√ß√£o:**

```bash
# Limpar checkpoints antes de reiniciar jobs
docker exec spark-master rm -rf /tmp/spark-checkpoint*
docker exec spark-master rm -rf /tmp/checkpoint-*
```

**Recomenda√ß√£o:**

- Implementar limpeza autom√°tica de checkpoints antigos
- Usar path com timestamp: `/tmp/checkpoint-eventos-$(date +%Y%m%d)`

---

## üìù DOCUMENTA√á√ÉO - Faltante ou Incompleta

### 4. `MCP_DOCUMENTATION.md`

**Status:** ‚úÖ Existe mas desatualizado  
**Problema:** N√£o menciona ferramentas de Supabase  
**Impacto:** Baixo - Usu√°rios podem n√£o saber como sincronizar

**Atualizar:**

- Adicionar se√ß√£o sobre `sync_leads_from_supabase()`
- Adicionar se√ß√£o sobre `sync_chat_sessions_from_supabase()`
- Adicionar se√ß√£o sobre `get_supabase_dashboard()`

### 5. `SUPABASE_INTEGRATION.md`

**Status:** ‚úÖ Existe e atualizado  
**Problema:** Nenhum  
**A√ß√£o:** Manter atualizado

### 6. `README.md` (principal)

**Status:** ‚ö†Ô∏è B√°sico demais  
**Problema:** N√£o explica como usar Superset/Kibana  
**Impacto:** M√©dio - Curva de aprendizado maior

**A√ß√£o Tomada:**

- ‚úÖ Criado `README_SISTEMA_COMPLETO.md` com guias detalhados

**Pr√≥ximo Passo:**

- Mesclar conte√∫do relevante no `README.md` principal
- Criar links entre documenta√ß√µes

---

## üîß CONFIGURA√á√ÉO - Requer Padroniza√ß√£o

### 7. `.env`

**Status:** ‚úÖ Funcional  
**Problema:** Credenciais em texto claro  
**Impacto:** Alto em produ√ß√£o

**Recomenda√ß√µes:**

1. Usar secret manager em produ√ß√£o
2. Adicionar `.env.example` (sem credenciais reais)
3. Validar vari√°veis ao iniciar o sistema

**Exemplo `.env.example`:**

```bash
# PostgreSQL
POSTGRES_USER=superset
POSTGRES_PASSWORD=CHANGE_ME
POSTGRES_DB=superset

# Supabase
SUPABASE_URL=https://YOUR_PROJECT.supabase.co
SUPABASE_ANON_KEY=YOUR_KEY_HERE
```

### 8. `docker-compose.yml`

**Status:** ‚úÖ Funcional  
**Problema:** Sem health checks em todos os servi√ßos  
**Impacto:** Baixo - Inicializa√ß√£o pode ter race conditions

**Melhorias Sugeridas:**

```yaml
# Adicionar health check para Kafka
kafka:
  healthcheck:
    test: kafka-broker-api-versions --bootstrap-server localhost:9092
    interval: 10s
    timeout: 10s
    retries: 5
```

---

## üß™ TESTES - Faltante ou Incompleto

### 9. `test_mcp.py`

**Status:** ‚úÖ Funcional  
**Problema:** N√£o testa integra√ß√£o Supabase  
**Impacto:** Baixo - Testes manuais necess√°rios

**Adicionar:**

```python
def test_supabase_sync():
    """Testar sincroniza√ß√£o do Supabase"""
    from supabase_to_kafka import sync_leads_to_kafka
    result = sync_leads_to_kafka(limit=1, hours_ago=720)
    assert result['status'] == 'success'
    assert result['total_processed'] >= 0
```

### 10. `test_supabase_integration.py`

**Status:** ‚úÖ Existe e funcional  
**Problema:** Nenhum  
**A√ß√£o:** Executar regularmente

---

## üìä MONITORAMENTO - Faltante

### 11. Logs Centralizados

**Status:** ‚ùå N√£o implementado  
**Problema:** Logs espalhados em m√∫ltiplos locais  
**Impacto:** M√©dio - Dificulta troubleshooting

**Logs Atuais:**

- Spark: `/tmp/spark_job.log`
- Containers: `docker logs <name>`
- Python: stdout

**Solu√ß√£o Sugerida:**

- Implementar ELK stack (Elasticsearch j√° existe)
- Ou usar Loki + Grafana
- Centralizar logs em volume Docker

### 12. M√©tricas de Performance

**Status:** ‚ùå N√£o implementado  
**Problema:** Sem visibilidade de throughput, lat√™ncia  
**Impacto:** M√©dio - Otimiza√ß√£o dif√≠cil

**Implementar:**

- Prometheus + Grafana
- JMX exporter para Kafka/Spark
- M√©tricas customizadas no MCP

---

## üîÑ CI/CD - Faltante

### 13. Pipeline de Deploy

**Status:** ‚ùå N√£o existe  
**Problema:** Deploy manual  
**Impacto:** M√©dio - Risco de erro humano

**Criar:**

- `.github/workflows/test.yml` - Testes automatizados
- `.github/workflows/deploy.yml` - Deploy para produ√ß√£o
- Script de valida√ß√£o pr√©-deploy

---

## üìã Checklist de Revis√£o

### Prioridade ALTA (Fazer Agora)

- [ ] Corrigir `spark_supabase.py` para funcionar
- [ ] Resolver duplica√ß√£o no Elasticsearch (`spark_app.py`)
- [ ] Limpar checkpoints antigos
- [ ] Criar `.env.example`

### Prioridade M√âDIA (Esta Semana)

- [ ] Atualizar `MCP_DOCUMENTATION.md` com ferramentas Supabase
- [ ] Adicionar testes de integra√ß√£o Supabase
- [ ] Implementar health checks completos no docker-compose
- [ ] Adicionar script de valida√ß√£o de ambiente

### Prioridade BAIXA (Quando Poss√≠vel)

- [ ] Implementar logs centralizados
- [ ] Adicionar m√©tricas de performance
- [ ] Criar pipeline CI/CD
- [ ] Migrar credenciais para secret manager

---

## üõ†Ô∏è Como Aplicar as Corre√ß√µes

### Passo 1: Corrigir spark_supabase.py

```bash
# 1. Revisar c√≥digo
code /home/renan3/SUPERSET/spark_supabase.py

# 2. Testar localmente
python3 spark_supabase.py

# 3. Resubmeter ao Spark
docker cp spark_supabase.py spark-master:/opt/spark-apps/
docker exec -d spark-master bin/spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.7.0 \
  /opt/spark-apps/spark_supabase.py
```

### Passo 2: Corrigir Duplica√ß√£o Elasticsearch

```bash
# Editar spark_app.py
code /home/renan3/SUPERSET/spark_app.py

# Adicionar na linha ~190:
# .option("es.mapping.id", "id")
# .option("es.write.operation", "upsert")

# Recarregar
docker cp spark_app.py spark-master:/opt/spark-apps/
# Reiniciar job (ver README_SISTEMA_COMPLETO.md)
```

### Passo 3: Limpar Checkpoints

```bash
docker exec spark-master rm -rf /tmp/spark-checkpoint*
docker exec spark-master rm -rf /tmp/checkpoint-*
```

---

## üìû Pr√≥ximos Passos

1. ‚úÖ README completo criado
2. ‚è≥ Corrigir `spark_supabase.py`
3. ‚è≥ Resolver duplica√ß√£o Elasticsearch
4. ‚è≥ Implementar testes automatizados
5. ‚è≥ Deploy em produ√ß√£o

---

**Respons√°vel pela Revis√£o:** Time de Desenvolvimento  
**Prazo Sugerido:** 7 dias √∫teis  
**Prioridade Geral:** M√âDIA-ALTA
