# üîó Integra√ß√£o Supabase ‚Üí Pipeline SUPERSET

Esta integra√ß√£o permite consumir dados do **Supabase (LOVABLE SITE)** e alimentar o pipeline de dados em tempo real do SUPERSET.

---

## üìä Fluxo de Dados

```text
LOVABLE SITE (Web) ‚Üí Supabase ‚Üí Bridge Python ‚Üí Kafka ‚Üí Spark ‚Üí Postgres/Elasticsearch
```

### Dados Capturados

- **Leads**: Informa√ß√µes de contatos capturados pelo chatbot
- **Chat Sessions**: Sess√µes de conversa√ß√£o com m√©tricas
- **Chat Messages**: Mensagens individuais (opcional)
- **Analytics**: M√©tricas agregadas do chatbot

---

## üöÄ In√≠cio R√°pido

### 1. Instalar Depend√™ncias

```bash
# Ativar venv
source venv/bin/activate

# Instalar cliente Supabase
pip install supabase
```

### 2. Verificar Conex√£o

```bash
python supabase_to_kafka.py stats
```

**Sa√≠da esperada:**
```json
{
  "total_leads": 42,
  "qualified_leads": 15,
  "qualification_rate": 35.71,
  "active_sessions": 3,
  "recent_leads_24h": 5,
  "supabase_url": "lpdskhiqmufonnnlmemg.supabase.co",
  "database": "LOVABLE SITE - APPNE IA"
}
```

### 3. Sincronizar Dados

```bash
# Sincronizar leads (√∫ltimas 24h, m√°ximo 100)
python supabase_to_kafka.py sync-leads 100

# Sincronizar sess√µes de chat
python supabase_to_kafka.py sync-sessions 50
```

---

## üõ†Ô∏è Ferramentas MCP Dispon√≠veis

### `get_supabase_dashboard()`

Obt√©m estat√≠sticas gerais do Supabase.

**Exemplo de sa√≠da:**
```
üìä Dashboard Supabase - LOVABLE SITE - APPNE IA

üéØ Leads:
   ‚Ä¢ Total de leads: 42
   ‚Ä¢ Leads qualificados (score ‚â• 50): 15
   ‚Ä¢ Taxa de qualifica√ß√£o: 35.71%
   ‚Ä¢ Leads nas √∫ltimas 24h: 5

üí¨ Sess√µes:
   ‚Ä¢ Sess√µes ativas: 3

üîó Conex√£o:
   ‚Ä¢ URL: lpdskhiqmufonnnlmemg.supabase.co
   ‚Ä¢ Status: ‚úÖ Conectado
```

---

### `sync_leads_from_supabase(limit=100, hours_ago=24)`

Sincroniza leads do Supabase para o Kafka.

**Par√¢metros:**
- `limit`: N√∫mero m√°ximo de leads (padr√£o: 100)
- `hours_ago`: Janela de tempo em horas (padr√£o: 24)

**Exemplo:**
```python
from superset_mcp import sync_leads_from_supabase

result = sync_leads_from_supabase(limit=50, hours_ago=12)
print(result)
```

**Sa√≠da:**
```
‚úÖ Sincroniza√ß√£o conclu√≠da!

üìä Resumo:
‚Ä¢ Total encontrado: 12 leads
‚Ä¢ Total enviado ao Kafka: 12 eventos
‚Ä¢ Per√≠odo: √öltimas 12h
‚Ä¢ Score mais alto: 85
‚Ä¢ Score m√©dio: 62.3

üìà Por Status:
   ‚Ä¢ qualificado: 7
   ‚Ä¢ novo: 3
   ‚Ä¢ em_contato: 2
```

---

### `sync_chat_sessions_from_supabase(limit=50, hours_ago=24)`

Sincroniza sess√µes de chat do Supabase para o Kafka.

**Par√¢metros:**
- `limit`: N√∫mero m√°ximo de sess√µes (padr√£o: 50)
- `hours_ago`: Janela de tempo em horas (padr√£o: 24)

**Exemplo:**
```python
from superset_mcp import sync_chat_sessions_from_supabase

result = sync_chat_sessions_from_supabase(limit=30, hours_ago=6)
print(result)
```

---

## üìã Estrutura de Dados

### Lead (Supabase)
```json
{
  "id": "uuid",
  "nome": "Jo√£o Silva",
  "email": "joao@example.com",
  "telefone": "+5511999999999",
  "nome_empresa": "Tech Corp",
  "nome_projeto": "Sistema Web",
  "interesse": ["desenvolvimento", "consultoria"],
  "score_qualificacao": 75,
  "status_lead": "qualificado",
  "origem": "chatbot",
  "utm_source": "google",
  "created_at": "2025-12-04T10:30:00"
}
```

### Evento Transformado (Kafka)
```json
{
  "id": "uuid",
  "usuario": "joao@example.com",
  "evento": "lead_qualificado",
  "valor": 75.0,
  "timestamp": "2025-12-04T10:30:00",
  "categoria": "vendas",
  "metadata": {
    "nome": "Jo√£o Silva",
    "empresa": "Tech Corp",
    "projeto": "Sistema Web",
    "interesses": ["desenvolvimento", "consultoria"],
    "origem": "chatbot",
    "utm_source": "google"
  }
}
```

---

## üîÑ Sincroniza√ß√£o Autom√°tica

Para sincronizar dados periodicamente, use um cron job ou systemd timer:

### Op√ß√£o 1: Cron (a cada hora)

```bash
# Editar crontab
crontab -e

# Adicionar linha:
0 * * * * cd /home/renan3/SUPERSET && source venv/bin/activate && python supabase_to_kafka.py sync-leads 100 >> /tmp/supabase_sync.log 2>&1
```

### Op√ß√£o 2: Script Python com Loop

Criar `sync_daemon.py`:
```python
import time
from supabase_to_kafka import sync_leads_to_kafka, sync_chat_sessions_to_kafka

while True:
    print("Iniciando sincroniza√ß√£o...")
    
    # Sync leads
    sync_leads_to_kafka(limit=100, hours_ago=1)
    
    # Sync sessions
    sync_chat_sessions_to_kafka(limit=50, hours_ago=1)
    
    print("Aguardando pr√≥xima execu√ß√£o (3600s)...")
    time.sleep(3600)  # 1 hora
```

Rodar em background:
```bash
nohup python sync_daemon.py > sync_daemon.log 2>&1 &
```

---

## üìà An√°lise de Dados

Ap√≥s sincronizar, os dados estar√£o dispon√≠veis em:

### 1. Postgres (Dados Brutos)

```sql
-- Ver √∫ltimos leads processados
SELECT * FROM eventos_raw 
WHERE categoria = 'vendas' 
ORDER BY timestamp DESC 
LIMIT 10;

-- Estat√≠sticas por status de lead
SELECT 
    metadata->>'status_lead' as status,
    COUNT(*) as total,
    AVG(valor::numeric) as score_medio
FROM eventos_raw
WHERE categoria = 'vendas'
GROUP BY metadata->>'status_lead';
```

### 2. Elasticsearch

```bash
# Buscar leads qualificados
curl "http://localhost:9200/eventos/_search?q=categoria:vendas AND evento:lead_qualificado&pretty"

# Agrega√ß√£o por origem
curl -X GET "localhost:9200/eventos/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "size": 0,
  "aggs": {
    "por_origem": {
      "terms": {
        "field": "metadata.origem.keyword"
      }
    }
  }
}'
```

### 3. Superset/Kibana

Acesse os dashboards para visualiza√ß√µes:
- **Superset**: http://localhost:8088
- **Kibana**: http://localhost:5601

---

## üêõ Troubleshooting

### Erro: "No module named 'supabase'"

```bash
source venv/bin/activate
pip install supabase
```

### Erro: "Connection refused" (Kafka)

Verificar se Kafka est√° rodando:
```bash
docker ps | grep kafka
docker logs kafka
```

### Erro: "Invalid credentials" (Supabase)

Verificar credenciais em `supabase_to_kafka.py`:
- `SUPABASE_URL`
- `SUPABASE_KEY`

### Leads n√£o aparecem no Postgres

1. Verificar se o Spark Job est√° rodando:
   ```bash
   docker logs spark-master | grep "KafkaSparkPostgresPipeline"
   ```

2. Consultar t√≥pico Kafka diretamente:
   ```bash
   docker exec kafka kafka-console-consumer \
     --topic eventos \
     --bootstrap-server localhost:9092 \
     --from-beginning \
     --max-messages 10
   ```

---

##  Exemplo de Uso Completo

```bash
# 1. Ativar ambiente
cd ~/SUPERSET
source venv/bin/activate

# 2. Verificar pipeline est√° rodando
docker compose ps

# 3. Ver estat√≠sticas do Supabase
python supabase_to_kafka.py stats

# 4. Sincronizar √∫ltimas 24h
python supabase_to_kafka.py sync-leads 100

# 5. Verificar dados no Postgres
psql -U superset -d superset -c "SELECT COUNT(*) FROM eventos_raw WHERE categoria='vendas';"

# 6. Usar ferramentas MCP
python -c "from superset_mcp import get_supabase_dashboard; print(get_supabase_dashboard())"
```

---

## üìù Credenciais

**Supabase (LOVABLE SITE):**
- URL: `https://lpdskhiqmufonnnlmemg.supabase.co`
- Project ID: `lpdskhiqmufonnnlmemg`
- Anon Key: (veja `env.txt` no workspace LOVABLE SITE)

**Tabelas Dispon√≠veis:**
- `leads`
- `chat_sessions`
- `chat_messages`
- `chatbot_analytics`
- `profiles`
- `auth.users`

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ Integra√ß√£o b√°sica implementada
2. ‚è≥ Adicionar filtragem por campos customizados
3. ‚è≥ Implementar sincroniza√ß√£o bidirecional (Postgres ‚Üí Supabase)
4. ‚è≥ Criar dashboards espec√≠ficos para leads
5. ‚è≥ Alertas autom√°ticos para leads de alto valor

---

**√öltima Atualiza√ß√£o:** 2025-12-04  
**Status:** ‚úÖ Funcional e testado
