# ğŸ¤– Servidor MCP SUPERSET - DocumentaÃ§Ã£o Completa

## ğŸ“– Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
3. [Ferramentas DisponÃ­veis](#ferramentas-disponÃ­veis)
4. [Guia de Uso](#guia-de-uso)
5. [Troubleshooting](#troubleshooting)
6. [Arquitetura](#arquitetura)

---

## ğŸ¯ VisÃ£o Geral

O **Servidor MCP SUPERSET** Ã© uma interface de controle baseada em MCP (Model Context Protocol) que permite gerenciar e monitorar o pipeline de dados em tempo real atravÃ©s de linguagem natural ou chamadas programÃ¡ticas.

### Capacidades

- ğŸ‘ï¸ **Observabilidade**: Monitore o status de todos os serviÃ§os (Kafka, Spark, Postgres, Elasticsearch)
- ğŸ’¾ **Acesso a Dados**: Consulte dados processados no Postgres e Elasticsearch
- ğŸ•¹ï¸ **Controle**: Reinicie serviÃ§os e injete eventos de teste
- ğŸ§ª **SimulaÃ§Ã£o**: Teste o pipeline com dados sintÃ©ticos

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.12+
- Docker e Docker Compose
- WSL2 (se estiver no Windows)

### Passo 1: Configurar Ambiente Virtual

```bash
cd ~/SUPERSET

# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
source venv/bin/activate
```

### Passo 2: Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

**Nota importante**: O projeto usa `kafka-python-ng` (versÃ£o mantida) em vez de `kafka-python` (descontinuada). Isso garante compatibilidade com Python 3.12+.

### Passo 3: Iniciar o Pipeline

```bash
# Subir todos os containers
docker-compose up -d

# Aguardar serviÃ§os ficarem prontos (30-60s)
docker-compose ps

# Criar tabelas no banco
./init_database.sh

# (Opcional) Inicializar Superset
./init_superset.sh
```

---

## ğŸ› ï¸ Ferramentas DisponÃ­veis

### Categoria: Observabilidade

#### `get_pipeline_status()`

Retorna o status de saÃºde de todos os containers.

**Retorno:**

```
ğŸŸ¢ **superset**: running (running)
ğŸŸ¢ **kafka**: running (running)
ğŸŸ¢ **spark-worker-1**: running (running)
ğŸŸ¢ **elasticsearch**: running (running)
ğŸŸ¢ **spark-master**: running (running)
ğŸŸ¢ **postgres**: running (running)
```

**LimitaÃ§Ãµes**: Requer acesso ao socket Docker (`/var/run/docker.sock`). No Windows, execute dentro do WSL.

---

#### `check_kafka_lag()`

Verifica conectividade com Kafka e lista tÃ³picos disponÃ­veis.

**Retorno:**

```
âœ… Kafka acessÃ­vel. TÃ³picos encontrados: eventos
```

**Uso**: DiagnÃ³stico rÃ¡pido de problemas de conectividade com Kafka.

---

#### `get_spark_metrics()`

ObtÃ©m mÃ©tricas do Spark Master via API REST.

**Retorno:**

```
âš¡ Spark Master (ALIVE): 1 Workers ativos, 0 AplicaÃ§Ãµes rodando.
```

**Porta**: `http://localhost:8080/json/`

---

### Categoria: Acesso a Dados

#### `query_raw_events(limit=5)`

Consulta os Ãºltimos N eventos brutos no Postgres.

**ParÃ¢metros:**

- `limit` (int): NÃºmero de eventos a retornar (padrÃ£o: 5)

**Retorno:**

```python
{
  'id': 'dc1e621b-bdfa-462f-9cef-9c07a964aa02',
  'usuario': 'manual_user',
  'evento': 'teste_mcp',
  'valor': 123.45,
  'timestamp': datetime(2025, 12, 4, 9, 45, 52),
  'categoria': 'teste_manual',
  'processado_em': datetime(2025, 12, 4, 12, 45, 52)
}
```

**Tabela consultada**: `eventos_raw`

---

#### `search_elasticsearch(query, index="eventos")`

Busca documentos no Elasticsearch usando sintaxe Lucene.

**ParÃ¢metros:**

- `query` (str): Query string (ex: `categoria:ecommerce AND valor:>500`)
- `index` (str): Nome do Ã­ndice (padrÃ£o: `eventos`)

**Exemplo:**

```python
search_elasticsearch("evento:compra", index="eventos")
```

---

### Categoria: Controle & SimulaÃ§Ã£o

#### `restart_service(service_name)`

Reinicia um container especÃ­fico.

**ParÃ¢metros:**

- `service_name` (str): Nome do serviÃ§o (ex: `spark-worker-1`, `kafka`)

**Retorno:**

```
ğŸ”„ ServiÃ§o 'spark-worker-1' reiniciado com sucesso!
```

**Uso**: RecuperaÃ§Ã£o rÃ¡pida de serviÃ§os travados.

---

#### `inject_event(evento_tipo, valor, usuario="manual_user")`

Injeta um evento manual no Kafka para teste.

**ParÃ¢metros:**

- `evento_tipo` (str): Tipo do evento (ex: `compra`, `login`)
- `valor` (float): Valor monetÃ¡rio associado
- `usuario` (str): Identificador do usuÃ¡rio (opcional)

**Retorno:**

```json
âœ… Evento injetado com sucesso: {
  "id": "8f385f27-7a41-459b-bea8-05718b6abe48",
  "usuario": "manual_user",
  "evento": "teste_mcp",
  "valor": 123.45,
  "timestamp": "2025-12-04T10:36:06.147737",
  "categoria": "teste_manual"
}
```

**Fluxo**: Kafka â†’ Spark Streaming â†’ Postgres/Elasticsearch

---

## ğŸ“˜ Guia de Uso

### Modo 1: Teste ProgramÃ¡tico

Execute o script de teste incluÃ­do:

```bash
python test_mcp.py
```

Este script testa todas as ferramentas sequencialmente.

---

### Modo 2: Servidor MCP

Inicie o servidor para uso com clientes MCP:

```bash
# Ativar venv
source venv/bin/activate

# Iniciar servidor
mcp run superset_mcp.py
```

O servidor ficarÃ¡ disponÃ­vel via stdio para clientes MCP (como Claude Desktop, Continue, etc.).

---

### Modo 3: ImportaÃ§Ã£o Direta

Use as ferramentas em seus prÃ³prios scripts:

```python
from superset_mcp import (
    get_pipeline_status,
    inject_event,
    query_raw_events
)

# Verificar status
status = get_pipeline_status()
print(status)

# Injetar evento de teste
inject_event(evento_tipo="compra", valor=250.00, usuario="teste123")

# Consultar dados
eventos = query_raw_events(limit=10)
print(eventos)
```

---

## ğŸ”§ Troubleshooting

### Problema: `ModuleNotFoundError: No module named 'kafka.vendor.six.moves'`

**Causa**: VersÃ£o antiga do `kafka-python` (2.0.2) incompatÃ­vel com Python 3.12+.

**SoluÃ§Ã£o**:

```bash
pip uninstall kafka-python
pip install kafka-python-ng
```

---

### Problema: `Error while fetching server API version: module 'socket' has no attribute 'AF_UNIX'`

**Causa**: Tentativa de acessar socket Docker do Windows (nÃ£o suportado).

**SoluÃ§Ã£o**: Execute o script dentro do WSL:

```bash
wsl
cd ~/SUPERSET
source venv/bin/activate
python test_mcp.py
```

---

### Problema: `externally-managed-environment`

**Causa**: Python 3.12+ no Ubuntu 24.04 nÃ£o permite instalaÃ§Ã£o global de pacotes.

**SoluÃ§Ã£o**: Use ambiente virtual (venv):

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### Problema: Containers nÃ£o sobem (`docker compose up` falha)

**DiagnÃ³stico**:

```bash
# Ver logs de erro
docker-compose logs

# Verificar se buildx estÃ¡ disponÃ­vel
docker buildx version
```

**SoluÃ§Ã£o alternativa**:

```bash
# Usar build tradicional
DOCKER_BUILDKIT=0 docker-compose up -d --build
```

---

### Problema: Spark Job nÃ£o processa dados

**DiagnÃ³stico**:

```bash
# Verificar se o job estÃ¡ rodando
docker exec spark-master ps aux | grep spark

# Ver logs do Spark
docker logs spark-master
```

**SoluÃ§Ã£o**: Submeter o job manualmente:

```bash
docker cp spark_app.py spark-master:/opt/spark-apps/
docker exec -it spark-master bin/spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.7.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
  /opt/spark-apps/spark_app.py
```

---

## ğŸ—ï¸ Arquitetura

### Fluxo de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Produtor  â”‚ (kafka_producer.py ou inject_event)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka    â”‚ (TÃ³pico: eventos)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Spark Stream â”‚ (spark_app.py)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Postgres â”‚   â”‚Postgres  â”‚  â”‚Elastic-  â”‚
â”‚eventos_  â”‚   â”‚eventos_  â”‚  â”‚search    â”‚
â”‚raw       â”‚   â”‚agregados â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚             â”‚
       â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Superset â”‚   â”‚ Superset â”‚  â”‚  Kibana  â”‚
â”‚Dashboardsâ”‚   â”‚Dashboardsâ”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes do MCP Server

```
superset_mcp.py
â”œâ”€â”€ Observabilidade
â”‚   â”œâ”€â”€ get_pipeline_status() â†’ Docker API
â”‚   â”œâ”€â”€ check_kafka_lag() â†’ Kafka Admin API
â”‚   â””â”€â”€ get_spark_metrics() â†’ Spark REST API
â”‚
â”œâ”€â”€ Dados
â”‚   â”œâ”€â”€ query_raw_events() â†’ Postgres (psycopg2)
â”‚   â””â”€â”€ search_elasticsearch() â†’ Elasticsearch REST API
â”‚
â””â”€â”€ Controle
    â”œâ”€â”€ restart_service() â†’ Docker API
    â””â”€â”€ inject_event() â†’ Kafka Producer API
```

---

## ğŸ“Š Portas e Endpoints

| ServiÃ§o        | Porta  | URL                          | Credenciais       |
|----------------|--------|------------------------------|-------------------|
| Spark Master   | 8080   | <http://localhost:8080>        | -                 |
| Spark Worker   | 8081   | <http://localhost:8081>        | -                 |
| Superset       | 8088   | <http://localhost:8088>        | admin / admin     |
| Kibana         | 5601   | <http://localhost:5601>        | -                 |
| PgAdmin        | 5050   | <http://localhost:5050>        | <admin@admin.com>   |
| Elasticsearch  | 9200   | <http://localhost:9200>        | -                 |
| Kafka          | 29092  | localhost:29092              | -                 |
| Postgres       | 5432   | localhost:5432               | superset/superset |

---

## ğŸ“ Exemplos PrÃ¡ticos

### Exemplo 1: Monitoramento Completo

```python
from superset_mcp import *

# 1. Verificar saÃºde do sistema
print(get_pipeline_status())

# 2. Verificar Kafka
print(check_kafka_lag())

# 3. Verificar Spark
print(get_spark_metrics())
```

### Exemplo 2: Teste End-to-End

```python
from superset_mcp import inject_event, query_raw_events
import time

# Injetar evento
inject_event("compra_teste", 99.99, "user_123")

# Aguardar processamento (Spark processa em micro-batches)
time.sleep(5)

# Verificar se chegou no banco
eventos = query_raw_events(limit=1)
print(eventos)
```

### Exemplo 3: RecuperaÃ§Ã£o de Falha

```python
from superset_mcp import get_pipeline_status, restart_service

# Verificar status
status = get_pipeline_status()

# Se algum serviÃ§o estiver down, reiniciar
if "ğŸ”´" in status:
    restart_service("spark-worker-1")
```

---

## ğŸ“ Notas de Desenvolvimento

### Testado em

- âœ… Ubuntu 24.04 (WSL2)
- âœ… Python 3.12.3
- âœ… Docker 27.x
- âœ… kafka-python-ng 2.2.3

### LimitaÃ§Ãµes Conhecidas

- `get_pipeline_status()` nÃ£o funciona no PowerShell (apenas WSL/Linux)
- Requer que o pipeline esteja rodando para testes completos
- Elasticsearch pode demorar ~60s para ficar "Healthy" na primeira inicializaÃ§Ã£o

---

## ğŸ¤ Contribuindo

Para adicionar novas ferramentas ao MCP:

1. Adicione a funÃ§Ã£o decorada com `@mcp.tool()` em `superset_mcp.py`
2. Documente a funÃ§Ã£o com docstring clara
3. Adicione testes em `test_mcp.py`
4. Atualize esta documentaÃ§Ã£o

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte do pipeline SUPERSET de dados em tempo real.
